Artificial intelligence (AI) systems are best suited to help companies explore and exploit the data that they have, simultaneously improving their business models and processes, a range of information technology (IT) experts say. The main improvements and benefits of AI derive from being able to interrogate huge volumes of unstructured data, extract useful information from it and help humans make decisions on this basis in an instant, says IT systems multinational IBM South Africa Watson and Cloud Platform sales lead Andrew Quixley. “One example would be getting a tax recommendation that takes into account all 74 000 pages of the US Tax Code.” Business analytics multinational SAS analytics director David Cosgrave concurs, noting that this means that AI systems are expected – at least over the medium term – to augment human capabilities and enable people to more effectively explore, evaluate and act on a much broader range of data than was possible before. “Human decisions, and the associated business functions, will be much more data-driven and grounded in information from a wide range of different sources. “AI is one of the ways that silos in businesses are being broken down. It is called ‘data democratisation’ and refers to business data used by all parts of a business, as well as data exploration tools used by all workers,” says Cosgrave. AI’s ability to interrogate unstructured information – such as text, images and video – means that, in future, it will be possible to search and find information stored in these formats as quickly and easily as you can search for numbers in a database today, highlights Quixley. “AI has almost unlimited potential to accelerate processes and automate simple decision-making, but that does not mean that AI is against the interests of human workers. Rather, AI is about augmenting human workers and empowering them to achieve far more than either humans or machines could do alone.” Multinational IT equipment manufacturer Lenovo South Africa and Southern African Development Community GM Thibault Dousson notes that 90% of the current data was created in the past two years and 1.7 MB of data is created per second per person. “We have only used a very small amount of all this data.” Similarly, US market research company Forrester principal analyst Boris Evelson highlights that the number of companies with more than 100 terabytes of unstructured data has doubled since 2016. “However, only 32% of companies have successfully analysed text data, and even fewer are analysing other unstructured sources. Deep learning will make data analysis more accurate and scalable,” he says. In 2018, AI will be responsible for decision-making and real-time instructions and recommendations for both employees and customers at 20% of all organisations. Systems will even suggest what to offer customers and the terms to offer suppliers, and issue instructions to staff. Data-driven decision-making will grow considerably over the next year, details Evelson. “However, AI is not a plug-and-play proposition. Unless firms plan, deploy and govern it correctly, new AI technology will provide meagre benefits at best or, at worst, result in unexpected and undesired outcomes,” he emphasises. Applications AI systems will be crucial for managing the volumes of data, as well as parsing the data to fit the process, especially for lay users, says Cosgrave. “There are thousands of possible uses for AI in business. AI can be used effectively in decision support systems for professionals in various domains, such as healthcare, finance, loan and credit and insurance,” says Quixley. “Simple AI applications can be built by calling prebuilt AI services from the cloud. No hardware is needed and elementary development skills would suffice.” Early applications of AI technology will include the intelligent automation of tasks where any of the steps require understanding a natural language and/or some human cognition to decide or choose the action or outcome. Chatbots for customer service is a good example; automatic assessment of insurance claims is another example, says Quixley. Council for Scientific and Industrial Research (CSIR) modelling and digital science researcher Dr Vukosi Marivate emphasises that businesses must determine what an AI system will be used for in the business and what they aim to optimise through the use of these systems. “The reason for this focus is to ensure that businesses understand what these AI systems can optimise and their limitations. It is not a ‘black box’ that can do anything, but an engineered system that performs specific functions that can add value only if they are suitable for the business. “Further, not achieving the outcomes expected will lead to AI and machine learning teams in companies being cut and the resources for AI research, development and innovation will also be cut. This will hamper the development and use of these systems, which can provide many significant benefits if correctly applied,” he says. Marivate highlights that one use of AI in Africa is to provide a public crop disease service for farmers. “The farmer takes pictures of the parts of plants that he or she believes display a symptom of a disease and then uploads those images to a public service provided by a national agricultural institution. The institution, which has an image recognition machine learning system, then compares the images to its database of plant diseases and visible symptoms, including images of these symptoms, and sends the farmer a report of the disease or diseases that the symptoms may indicate. The farmer can then treat the disease. This example of an AI system, even though it is specifically a machine learning system, helps to improve yields, food security and the performance of the farmer’s business, all without the farmer having to take samples to a laboratory. Practical applications to analyse unstructured data to provide useful outputs are good candidates for AI systems, he says. Machine learning is a component and significant subset of AI systems, and is focused on enabling machines to evaluate unstructured information that people can usually evaluate easily. “AI systems are probabilistic,” explains Cosgrave, “which means that their accuracy is not perfect. This is one of the reasons why they will typically be applied to augment the capabilities of people, who will still make the final decision on the validity of the output.” Development and Deployment However, much as business models are re-evaluated and changed, the algorithms used in business processes, as well as AI systems, must be regularly retrained and updated, he says. “The algorithms, analytics and AI systems must be done by experts to ensure that they do not use incorrect data or weight the data incorrectly, for example. While the engagement with the data and the insights gleaned from it will be a combination of a user exploring the data and the AI system processing the data, the development and updating of the system must be done by technical experts.” Highly technical uses will likely need custom development, which would generally require highly skilled developers, confirms Quixley. “As the insight market becomes more complex, data and analytics decision-makers should reassess strategies and begin partnering with vendors and other partners,” states Evelson.
Up to 80% of organisations will rely on ‘insights service providers’ for at least some portion of their capabilities in 2018, driving business for insights service providers, management consultants and systems integrators. Academia will also become a key insight partner for enterprises, he highlights. Control and Trust As with any system developed by human beings, there is potential for bias in AI. Programmers have to be aware of potential bias and the role it plays in determining outcomes. One risk of using AI is training a machine learning model using data that contains human bias or that suggests humans make unfair decisions, highlights Quixley. “We have to think about these issues and how the hidden biases of society can be introduced through algorithms, training methods and data sets,” he states. “Our responsibility is to make sure that data sets used for training and AI models are not biased, which is how trust is built. In principle, any system could be taught anything. We are looking at new techniques to instil ethical principles in AI systems, allowing systems to make decisions consistent with underlying ethical principles. “However, it becomes complicated, mainly because there is no universally accepted ethical system for AI. We have to constantly question which values we use and how we navigate the pitfalls of self-selecting bias. IBM’s approach is to create a set of rules with which the system must comply and then, over time, identify subtler, ethically ambiguous situations, as well as accept input on how to handle those situations going forward,” says Quixley. Marivate notes that AI systems should be engineered to be fault tolerant and not fail at the first mistake or incorrect piece of data. “The performance of AI systems must be measured regularly like any other industrial and commercial systems. Similarly, refining the system to more accurately deal with edge cases – cases where the algorithm does not produce consistent or accurate results – is also important, as some of these edge cases can be used to fool an AI system or cause incorrect advice, products or outputs to be produced and possibly used.” Additionally, there must be ways to audit and evaluate AI systems, especially when dealing with sensitive use cases, such as medical and personal data. “Regulation of AI systems should take into account the intended application and the potential impacts of the functions the system performs. For example, AI systems in financial organisations (which function in a heavily regulated industry) will have to comply with financial regulations. In less regulated or unregulated industries and use cases, there is a need for tools and methods to make it clear how the system produces its outputs.” Businesses will need to prove or at least provide a breakdown of how an AI system arrives at its decisions. These audit tools will also serve to evaluate its performance and, over time, its updating and improvement, states Marivate. For people to trust computer decisions, ethical or otherwise, people must know how an AI system arrives at its conclusions and recommendations. To gain significant trust, AI systems must be able to explain why they are recommending something. Transparency is key to fostering trust and improving the positive impact of AI systems, adds Quixley. Marivate points out that the Deep Learning Indaba, to be held in September in Stellenbosch, will have several panels on AI ethics and design, as well as seminars on the development and use of the systems for specific industries.